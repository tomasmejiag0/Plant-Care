"""
FastAPI Server - PlantCare AI Backend
API REST para an√°lisis de plantas usando arquitectura multi-agente
"""
import os
import sys
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
from pathlib import Path
import shutil
from dotenv import load_dotenv

# Agregar src al path
sys.path.append('src')
sys.path.append('src/agentes')

from agentes.agente_respuesta import ResponseAgent
# Importar versi√≥n con LangChain para cumplir requisitos acad√©micos
try:
    from agentes.agente_respuesta_langchain import ResponseAgentLangChain
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("‚ö† LangChain no disponible, usando implementaci√≥n manual")

load_dotenv()

# Inicializar FastAPI
app = FastAPI(
    title="PlantCare AI API",
    description="API de an√°lisis inteligente de plantas usando multi-agentes",
    version="1.0.0"
)

# Configurar CORS para permitir peticiones desde el navegador
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En producci√≥n, especificar dominios exactos
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Directorio para uploads temporales
UPLOAD_DIR = Path("uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# Inicializar sistema multi-agente (global)
response_agent = None
response_agent_langchain = None
gemini_available = False
gemini_vision_available = False
local_llm = None

@app.on_event("startup")  # Deprecated pero funcional - mantener para compatibilidad
async def startup_event():
    """Inicializa el sistema al arrancar"""
    global response_agent, response_agent_langchain, gemini_available, gemini_vision_available, local_llm
    print("\nüöÄ Iniciando PlantCare AI Backend...")
    
    # Inicializar agente tradicional
    use_supabase = os.getenv("SUPABASE_URL") and os.getenv("SUPABASE_KEY")
    response_agent = ResponseAgent(use_supabase=use_supabase)
    
    # Verificar disponibilidad de Gemini
    gemini_available = response_agent.llm is not None
    gemini_vision_available = response_agent.vision_agent.gemini_model is not None
    
    # Intentar inicializar LLM local como fallback (siempre, incluso si Gemini est√° disponible)
    try:
        from src.local_llm import get_local_llm
        local_llm = get_local_llm()
        if local_llm:
            print(f"[OK] LLM local disponible ({local_llm.model}) - disponible como respaldo")
        else:
            print("[INFO] LLM local no disponible - se usar√° solo documentos si Gemini falla")
    except Exception as e:
        print(f"[WARN] Error inicializando LLM local: {e}")
        local_llm = None
    
    if not gemini_available:
        if local_llm:
            print("[OK] Usando LLM local como principal (Gemini no disponible)")
        else:
            print("[WARN] Gemini LLM no disponible y LLM local no disponible - sistema funcionar√° solo con documentos")
    
    if not gemini_vision_available:
        print("‚ö†Ô∏è Gemini Vision no disponible - an√°lisis de im√°genes deshabilitado")
    
    # Inicializar agente con LangChain (para cumplir requisitos acad√©micos)
    if LANGCHAIN_AVAILABLE:
        try:
            response_agent_langchain = ResponseAgentLangChain(use_supabase=use_supabase)
            print("‚úì Agente LangChain inicializado")
        except Exception as e:
            print(f"‚ö† Error inicializando LangChain agent: {e}")
            response_agent_langchain = None
    
    print("‚úÖ Backend listo para recibir peticiones\n")


# Modelos Pydantic
class HealthResponse(BaseModel):
    status: str
    message: str

class ChatMessage(BaseModel):
    role: str  # 'user' or 'assistant'
    content: str

class ChatRequest(BaseModel):
    message: str
    history: list[ChatMessage] = []

class ChatResponse(BaseModel):
    success: bool
    response: str
    error: str = None


@app.get("/", response_model=HealthResponse)
async def root():
    """Endpoint ra√≠z"""
    return {
        "status": "online",
        "message": "PlantCare AI API est√° funcionando üå±"
    }


@app.get("/api/health", response_model=HealthResponse)
async def health_check():
    """Health check del API"""
    return {
        "status": "healthy",
        "message": "API operativa"
    }

@app.get("/api/capabilities")
async def get_capabilities():
    """
    Endpoint para verificar qu√© capacidades est√°n disponibles
    √ötil para el frontend para saber qu√© funciones habilitar/deshabilitar
    """
    global gemini_available, gemini_vision_available
    
    return {
        "gemini_llm_available": gemini_available,
        "gemini_vision_available": gemini_vision_available,
        "image_analysis_available": gemini_vision_available,  # Requiere Gemini Vision
        "chat_available": True,  # Siempre disponible (usa documentos si no hay LLM)
        "message": "Capacidades del sistema"
    }


@app.post("/api/analyze-plant")
async def analyze_plant(
    image: UploadFile = File(..., description="Imagen de la planta"),
    user_actions: str = Form("", description="Descripci√≥n de acciones del usuario con la planta")
):
    """
    Endpoint principal: Analiza una imagen de planta
    
    Par√°metros:
    - image: Archivo de imagen (JPEG, PNG)
    - user_actions: Texto describiendo qu√© ha hecho el usuario con la planta
    
    Retorna:
    - An√°lisis completo de la planta con recomendaciones
    """
    global gemini_vision_available
    
    # Verificar si Gemini Vision est√° disponible
    if not gemini_vision_available:
        raise HTTPException(
            status_code=503,
            detail={
                "error": "image_analysis_unavailable",
                "message": "El an√°lisis de im√°genes no est√° disponible en este momento. Por favor, usa el chat de texto para hacer preguntas sobre cuidado de plantas."
            }
        )
    
    try:
        # Validar formato de imagen
        if not image.content_type.startswith('image/'):
            raise HTTPException(
                status_code=400,
                detail="El archivo debe ser una imagen"
            )
        
        # Guardar imagen temporalmente con nombre √∫nico
        import time
        import uuid
        file_extension = Path(image.filename).suffix or '.jpg'
        unique_id = f"{int(time.time())}_{uuid.uuid4().hex[:8]}"
        temp_file_path = UPLOAD_DIR / f"temp_plant_{unique_id}{file_extension}"
        
        with open(temp_file_path, "wb") as buffer:
            shutil.copyfileobj(image.file, buffer)
        
        print(f"\nüì∏ Imagen recibida: {image.filename} (guardada como {temp_file_path.name})")
        print(f"üìù Acciones del usuario: {user_actions if user_actions else '(ninguna)'}")
        
        # Ejecutar sistema multi-agente
        result = response_agent.execute(
            image_path=str(temp_file_path),
            user_actions=user_actions
        )
        
        # Limpiar archivo temporal (Windows fix: asegurar que est√° cerrado)
        try:
            if temp_file_path.exists():
                import time
                time.sleep(0.1)  # Peque√±a pausa para Windows
                temp_file_path.unlink()
        except Exception as e:
            print(f"‚ö† No se pudo eliminar archivo temporal: {e}")
        
        if result.get('success'):
            return JSONResponse(
                status_code=200,
                content=result
            )
        else:
            raise HTTPException(
                status_code=500,
                detail=result.get('error', 'Error en an√°lisis')
            )
    
    except HTTPException:
        raise
    except Exception as e:
        error_str = str(e)
        print(f"‚ùå Error: {e}")
        
        # Detectar si es error de quota o servicio no disponible
        is_quota_error = (
            "429" in error_str or 
            "ResourceExhausted" in error_str or 
            "quota" in error_str.lower() or
            "exceeded" in error_str.lower()
        )
        
        if is_quota_error:
            # Deshabilitar Gemini Vision para evitar m√°s intentos
            response_agent.vision_agent.gemini_model = None
            gemini_vision_available = False
            
            raise HTTPException(
                status_code=503,
                detail={
                    "error": "image_analysis_unavailable",
                    "message": "El an√°lisis de im√°genes no est√° disponible en este momento debido a limitaciones del servicio. Por favor, usa el chat de texto para hacer preguntas sobre cuidado de plantas."
                }
            )
        
        raise HTTPException(
            status_code=500,
            detail=f"Error procesando imagen: {str(e)}"
        )


@app.post("/api/chat")
async def chat(request: ChatRequest):
    """
    Endpoint de chat con RAG - Responde preguntas usando la base de conocimiento
    
    Par√°metros:
    - message: Mensaje del usuario
    - history: Historial de conversaci√≥n (opcional)
    
    Retorna:
    - Respuesta del agente basada en la base de conocimiento
    """
    global local_llm
    try:
        print(f"\nüí¨ Chat request recibido")
        print(f"üìù Mensaje: {request.message}")
        print(f"üìö Historial: {len(request.history)} mensajes")
        
        # Usar el knowledge agent para buscar informaci√≥n relevante
        knowledge_agent = response_agent.knowledge_agent
        
        # Verificar si la pregunta es sobre plantas ANTES de buscar
        message_lower = request.message.lower().strip()
        
        # Detectar preguntas conceptuales generales que no son sobre cuidado de plantas
        conceptual_questions = [
            'que es una', 'que es un', 'que es el', 'que es la', 'que son las', 'que son los',
            'que significa', 'definicion', 'definici√≥n', 'concepto de', 'que quiere decir'
        ]
        
        is_conceptual_general = any(pattern in message_lower for pattern in conceptual_questions)
        
        # Palabras clave espec√≠ficas de cuidado de plantas (no solo palabras relacionadas)
        plant_care_keywords = ['riego', 'cuidado', 'cuidar', 'mantener', 'regar', 'suelo', 'tierra',
                               'luz', 'sol', 'sombra', 'maceta', 'trasplante', 'poda', 'fertilizante',
                               'enfermedad', 'plaga', 'problema', 'hoja amarilla', 'hoja marron',
                               'como cuidar', 'como mantener', 'como regar', 'cuando regar',
                               'suculenta', 'cactus', 'bonsai', 'orquidea', 'helecho']
        
        # Verificar si es una pregunta sobre cuidado de plantas espec√≠ficamente
        is_plant_care_question = any(keyword in message_lower for keyword in plant_care_keywords)
        
        # Si es una pregunta conceptual general sin contexto de cuidado, responder directamente
        if is_conceptual_general and not is_plant_care_question:
            return JSONResponse(
                status_code=200,
                content={
                    "success": True,
                    "response": "Soy un asistente especializado en el cuidado pr√°ctico de plantas. Puedo ayudarte con:\n\n‚Ä¢ C√≥mo cuidar diferentes tipos de plantas\n‚Ä¢ Problemas comunes y sus soluciones\n‚Ä¢ Recomendaciones de riego, luz y suelo\n‚Ä¢ Identificaci√≥n de problemas de salud\n‚Ä¢ Propagaci√≥n y trasplante\n\nSi tienes una pregunta espec√≠fica sobre c√≥mo cuidar una planta, estar√© encantado de ayudarte. Por ejemplo: '¬øC√≥mo cuido una suculenta?' o '¬øCu√°ndo debo regar mi planta?'"
                }
            )
        
        # Verificar si tiene palabras relacionadas con plantas (para b√∫squeda)
        plant_keywords = ['planta', 'flor', 'hoja', 'jard√≠n', 'verde', 'semilla', 'ra√≠z', 'tallo']
        has_plant_keyword = any(keyword in message_lower for keyword in plant_keywords)
        
        # Si no tiene ninguna relaci√≥n con plantas, responder directamente
        if not has_plant_keyword and not is_plant_care_question:
            return JSONResponse(
                status_code=200,
                content={
                    "success": True,
                    "response": "Lo siento, pero esa pregunta no est√° relacionada con plantas. Soy un asistente especializado en cuidado de plantas. Puedo ayudarte con:\n\n‚Ä¢ Identificaci√≥n de plantas\n‚Ä¢ Cuidado y mantenimiento\n‚Ä¢ Problemas de salud de plantas\n‚Ä¢ Recomendaciones de riego, luz y suelo\n‚Ä¢ Tratamiento de plagas\n\n¬øTienes alguna pregunta sobre plantas que pueda ayudarte a resolver?"
                }
            )
        
        # Buscar en la base de conocimiento
        documents = knowledge_agent.search_direct(request.message, top_k=5)
        
        # Debug: mostrar documentos encontrados
        if documents:
            print(f"üìä Documentos encontrados: {len(documents)}")
            for i, doc in enumerate(documents[:3]):
                print(f"  Doc {i+1}: relevancia={doc['relevance_score']:.3f}, fuente={doc.get('source', 'N/A')[:50]}")
                print(f"    Texto preview: {doc.get('text', '')[:100]}...")
        else:
            print("‚ö†Ô∏è No se encontraron documentos")
        
        # Verificar relevancia de los documentos encontrados
        if documents:
            max_relevance = max([d['relevance_score'] for d in documents])
            print(f"üìà Relevancia m√°xima: {max_relevance:.3f}")
            # Si la relevancia es muy baja (< 0.3), los documentos probablemente no son relevantes
            if max_relevance < 0.3:
                print(f"‚ö†Ô∏è Relevancia m√°xima muy baja: {max_relevance:.3f}")
                # A√∫n as√≠, intentar usar los documentos si hay alguno con relevancia > 0.25
                if max_relevance >= 0.25:
                    print(f"üìù Usando documentos con relevancia baja pero aceptable")
                else:
                    return JSONResponse(
                        status_code=200,
                        content={
                            "success": True,
                            "response": f"Lo siento, no encontr√© informaci√≥n espec√≠fica sobre '{request.message}' en mi base de conocimiento sobre cuidado de plantas. Puedo ayudarte con:\n\n‚Ä¢ Cuidado de suculentas, cactus, plantas de interior\n‚Ä¢ Problemas comunes de plantas\n‚Ä¢ Riego, luz y suelo\n‚Ä¢ Propagaci√≥n y trasplante\n\n¬øTe gustar√≠a hacer una pregunta m√°s espec√≠fica sobre cuidado de plantas? Por ejemplo: '¬øC√≥mo cuido una suculenta?'"
                        }
                    )
        
        # Construir contexto del historial
        history_context = ""
        if request.history:
            history_context = "\n".join([
                f"{'Usuario' if msg.role == 'user' else 'Asistente'}: {msg.content}"
                for msg in request.history[-6:]  # √öltimos 6 mensajes
            ])
        
        # Construir contexto de conocimiento (texto completo de documentos m√°s relevantes)
        knowledge_context = ""
        if documents:
            # Limpiar el texto de los documentos antes de pasarlo al LLM
            import re
            cleaned_docs = []
            for doc in documents[:3]:  # Top 3 documentos
                doc_text = doc['text']
                # Limpiar markdown de los documentos tambi√©n
                doc_text = re.sub(r'^#{1,6}\s+', '', doc_text, flags=re.MULTILINE)
                doc_text = re.sub(r'#{1,6}\s+', '', doc_text)
                # Limpiar puntos suspensivos
                doc_text = re.sub(r'\.\.\.+', '', doc_text)
                cleaned_docs.append({
                    'text': doc_text,
                    'score': doc['relevance_score']
                })
            
            # Usar texto limpio pero organizado
            knowledge_context = "\n\n--- INFORMACI√ìN DE REFERENCIA ---\n\n".join([
                f"Fuente {i+1} (Relevancia: {doc['score']:.2f}):\n{doc['text']}"
                for i, doc in enumerate(cleaned_docs)
            ])
        else:
            # No se encontraron documentos relevantes
            knowledge_context = "No se encontr√≥ informaci√≥n relevante en la base de conocimiento sobre esta pregunta."
        
        # Usar LLM para generar respuesta
        if response_agent.llm:
            print("ü§ñ Usando LLM para generar respuesta")
            prompt = f"""Eres un experto en cuidado de plantas hablando directamente con un amigo que te pregunta sobre plantas. Responde de forma completamente natural y conversacional.

‚ö†Ô∏è REGLAS ABSOLUTAS - NO PUEDES ROMPER ESTAS:
1. NUNCA uses s√≠mbolos # ## ### #### ##### ###### en tu respuesta - est√° completamente prohibido
2. NUNCA copies texto directamente - SIEMPRE explica con tus propias palabras de forma natural
3. NUNCA uses frases como "Bas√°ndome en", "Seg√∫n", "De acuerdo a" - responde directamente
4. NUNCA dejes respuestas incompletas o truncadas - completa TODO lo que vas a explicar
5. NUNCA uses formato t√©cnico o de documento - solo lenguaje conversacional normal

FORMATO DE RESPUESTA CORRECTO:
- Comienza respondiendo directamente la pregunta
- Usa p√°rrafos normales y fluidos (no t√≠tulos, no secciones)
- Si hay pasos o listas, usa vi√±etas (‚Ä¢) o n√∫meros (1. 2. 3.) de forma natural dentro del texto
- Explica todo completamente antes de terminar
- Puedes usar emojis ocasionalmente (üå±üíß‚òÄÔ∏èüåø)
- Termina con una pregunta amigable opcional

EJEMPLO INCORRECTO (NO HAGAS ESTO):
"# Cuidado de Suculentas
## Descripci√≥n General
Las suculentas son plantas que almacenan agua...
## Propagaci√≥n
1. Usar tierra..."

EJEMPLO CORRECTO (HAZ ESTO):
"Las suculentas son plantas incre√≠bles que almacenan agua en sus hojas y tallos, lo que las hace muy resistentes. Son perfectas para principiantes porque requieren muy poco mantenimiento.

Para cuidarlas correctamente, aqu√≠ tienes lo m√°s importante:

‚Ä¢ Riego: Solo riega cuando la tierra est√© completamente seca. En invierno puede ser cada 2-4 semanas.

‚Ä¢ Luz: Necesitan al menos 6 horas de luz solar directa al d√≠a.

‚Ä¢ Suelo: Usa una mezcla especial para cactus con buen drenaje.

Si quieres propagarlas, puedes cortar una hoja, dejarla secar unos d√≠as, y luego plantarla. En 4-12 semanas deber√≠as ver ra√≠ces nuevas.

¬øTe gustar√≠a saber m√°s sobre alg√∫n aspecto espec√≠fico?"

HISTORIAL DE CONVERSACI√ìN:
{history_context if history_context else "Primera pregunta del usuario."}

INFORMACI√ìN DE REFERENCIA DE SUPABASE (usa esto SOLO para entender el tema, luego explica TODO con tus propias palabras de forma natural):
{knowledge_context}

‚ö†Ô∏è IMPORTANTE: NO copies texto directamente de la informaci√≥n de referencia. NO uses t√≠tulos como "Descripci√≥n General", "Propagaci√≥n por Semillas", "Ventajas", "Desventajas", etc. Explica TODO con tus propias palabras de forma conversacional y natural.

PREGUNTA DEL USUARIO: {request.message}

IMPORTANTE: Responde SOLO con texto normal, sin s√≠mbolos #, sin copiar texto, explicando todo con tus propias palabras de forma natural y completa. Responde ahora:"""

            try:
                # Configurar par√°metros para respuestas m√°s completas y naturales
                import google.generativeai as genai
                try:
                    generation_config = genai.types.GenerationConfig(
                        temperature=0.9,  # M√°s creatividad para respuestas naturales y parafraseadas
                        top_p=0.95,
                        top_k=40,
                        max_output_tokens=2048,  # Respuestas m√°s largas y completas
                    )
                except:
                    # Fallback si GenerationConfig no est√° disponible
                    generation_config = {
                        "temperature": 0.9,
                        "top_p": 0.95,
                        "top_k": 40,
                        "max_output_tokens": 2048,
                    }
                
                # Intentar generar respuesta hasta 2 veces si contiene markdown
                max_attempts = 2
                response_text = None
                
                for attempt in range(max_attempts):
                    response = response_agent.llm.generate_content(
                        prompt,
                        generation_config=generation_config
                    )
                    response_text = response.text.strip()
                    
                    # Verificar si tiene markdown
                    if not re.search(r'#{1,6}\s+', response_text):
                        break  # Respuesta limpia, salir del loop
                    elif attempt < max_attempts - 1:
                        print(f"‚ö†Ô∏è Intento {attempt + 1}: Respuesta contiene markdown, regenerando...")
                        # Agregar instrucci√≥n adicional al prompt
                        prompt += "\n\nRECUERDA: NO uses s√≠mbolos # en tu respuesta. Responde solo con texto normal."
                    else:
                        print("‚ö†Ô∏è Respuesta a√∫n contiene markdown despu√©s de m√∫ltiples intentos")
                
                if not response_text:
                    response_text = response.text.strip()
                
                # Validar si la respuesta contiene markdown - si es as√≠, limpiar agresivamente
                import re
                has_markdown = bool(re.search(r'#{1,6}\s+', response_text))
                
                if has_markdown:
                    print("‚ö†Ô∏è Respuesta contiene markdown, aplicando limpieza agresiva...")
                
                # Limpieza MUY agresiva de markdown y texto truncado
                
                # PRIMERO: Detectar y eliminar fragmentos que parecen venir directamente de documentos
                # Patrones que indican texto copiado de documentos
                document_patterns = [
                    r'Cuidado de [A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±\s]+ Descripci√≥n General',
                    r'Descripci√≥n General[:\s]*',
                    r'Propagaci√≥n por Semillas[:\s]*',
                    r'Ventajas[:\s]*-',
                    r'Desventajas[:\s]*-',
                    r'M√©todo B√°sico[:\s]*\d+\.',
                    r'Problemas Comunes[:\s]*-',
                    r'Trasplante Frecuencia[:\s]*-',
                    r'Procedimiento[:\s]*\d+\.',
                ]
                for pattern in document_patterns:
                    response_text = re.sub(pattern, '', response_text, flags=re.IGNORECASE | re.MULTILINE)
                
                # Eliminar l√≠neas que son claramente t√≠tulos de documentos
                lines = response_text.split('\n')
                cleaned_lines = []
                skip_until_content = False
                for line in lines:
                    stripped = line.strip()
                    # Detectar t√≠tulos de documentos comunes
                    if any(title in stripped for title in ['Descripci√≥n General', 'Propagaci√≥n por Semillas', 
                                                           'Ventajas', 'Desventajas', 'M√©todo B√°sico', 
                                                           'Problemas Comunes', 'Trasplante Frecuencia', 'Procedimiento']):
                        skip_until_content = True
                        continue
                    # Si encontramos contenido real despu√©s de un t√≠tulo, dejar de saltar
                    if skip_until_content and len(stripped) > 20 and not re.match(r'^[\d\.\-\‚Ä¢\*]+', stripped):
                        skip_until_content = False
                    if not skip_until_content:
                        cleaned_lines.append(line)
                response_text = '\n'.join(cleaned_lines)
                
                # Eliminar TODOS los headers de markdown (# ## ### #### ##### ######) - m√∫ltiples pasos
                response_text = re.sub(r'^#{1,6}\s+', '', response_text, flags=re.MULTILINE)
                response_text = re.sub(r'#{1,6}\s+', '', response_text)  # En cualquier lugar
                response_text = re.sub(r'#+', '', response_text)  # Cualquier secuencia de #
                
                # Eliminar puntos suspensivos (truncados)
                response_text = re.sub(r'\.\.\.+', '', response_text)
                response_text = re.sub(r'\.\.\.\s*$', '', response_text, flags=re.MULTILINE)
                
                # Eliminar frases gen√©ricas comunes
                phrases_to_remove = [
                    r'Bas√°ndome en la informaci√≥n disponible[:\s]*',
                    r'Seg√∫n los documentos[:\s]*',
                    r'Seg√∫n la informaci√≥n[:\s]*',
                    r'De acuerdo a[:\s]*',
                    r'Bas√°ndome en[:\s]*',
                    r'De acuerdo con[:\s]*',
                    r'Con base en[:\s]*',
                    r'Propagaci√≥n por Semillas',
                    r'Ventajas',
                    r'Desventajas',
                    r'M√©todo B√°sico'
                ]
                for phrase in phrases_to_remove:
                    response_text = re.sub(phrase, '', response_text, flags=re.IGNORECASE)
                
                # Procesar l√≠neas para eliminar formato t√©cnico y fragmentos de documentos
                lines = response_text.split('\n')
                cleaned_lines = []
                skip_next = False
                
                # Lista de frases que indican texto copiado de documentos
                document_indicators = [
                    'Descripci√≥n General', 'Propagaci√≥n por Semillas', 'Ventajas', 'Desventajas',
                    'M√©todo B√°sico', 'Problemas Comunes', 'Trasplante Frecuencia', 'Procedimiento',
                    'Cuidado de Suculentas', 'Cuidado de Cactus', 'Plantas de Interior Comunes'
                ]
                
                for i, line in enumerate(lines):
                    stripped = line.strip()
                    
                    # Saltar l√≠neas vac√≠as
                    if not stripped:
                        if cleaned_lines and cleaned_lines[-1].strip():  # Solo agregar si la anterior no estaba vac√≠a
                            cleaned_lines.append('')
                        continue
                    
                    # Eliminar l√≠neas que contienen indicadores de documentos
                    if any(indicator in stripped for indicator in document_indicators):
                        # Si es solo el t√≠tulo sin contenido adicional, saltarlo
                        if len(stripped) < 50 or stripped in document_indicators:
                            continue
                        # Si tiene contenido adicional, intentar limpiarlo
                        for indicator in document_indicators:
                            stripped = stripped.replace(indicator, '').strip()
                    
                    # Eliminar l√≠neas que son solo n√∫meros, vi√±etas o muy cortas
                    if re.match(r'^[\d\.\-\‚Ä¢\*]+$', stripped) or len(stripped) < 4:
                        continue
                    
                    # Eliminar l√≠neas que parecen t√≠tulos t√©cnicos (todo en may√∫sculas y cortas)
                    if stripped.isupper() and len(stripped) < 50 and len(stripped.split()) < 5:
                        continue
                    
                    # Si la l√≠nea anterior era un n√∫mero/vi√±eta y esta parece ser continuaci√≥n, unirlas
                    if cleaned_lines and re.match(r'^\d+\.', cleaned_lines[-1].strip()):
                        cleaned_lines[-1] += ' ' + stripped
                    else:
                        cleaned_lines.append(stripped if stripped else line)
                
                response_text = '\n'.join(cleaned_lines)
                
                # Limpiar espacios m√∫ltiples y saltos de l√≠nea
                response_text = re.sub(r'\n{3,}', '\n\n', response_text)
                response_text = re.sub(r' {2,}', ' ', response_text)
                response_text = response_text.strip()
                
                # Si la respuesta todav√≠a contiene markdown despu√©s de la limpieza, eliminarlo completamente
                if '#' in response_text:
                    # Dividir por l√≠neas y eliminar las que tienen # o que parecen t√≠tulos
                    final_lines = []
                    for line in response_text.split('\n'):
                        stripped = line.strip()
                        # Eliminar l√≠neas con # o que parecen t√≠tulos t√©cnicos
                        if '#' not in stripped and not re.match(r'^[A-Z√Å√â√ç√ì√ö√ë\s]{3,50}$', stripped):
                            # Tambi√©n eliminar l√≠neas que son solo palabras en may√∫sculas (t√≠tulos)
                            if not (stripped.isupper() and len(stripped.split()) < 5):
                                final_lines.append(line)
                    response_text = '\n'.join(final_lines).strip()
                
                # Eliminar frases espec√≠ficas que aparecen en las respuestas problem√°ticas
                problematic_phrases = [
                    'Propagaci√≥n por Semillas',
                    'Ventajas',
                    'Desventajas',
                    'M√©todo B√°sico',
                    'Descripci√≥n General',
                    'Cuidado de Suculentas',
                    'Cuidado de Cactus',
                    'Plantas de Interior Comunes',
                ]
                for phrase in problematic_phrases:
                    # Eliminar la frase completa y su contexto
                    response_text = re.sub(rf'^{re.escape(phrase)}[:\s]*\n?', '', response_text, flags=re.MULTILINE | re.IGNORECASE)
                    response_text = re.sub(rf'\n{re.escape(phrase)}[:\s]*\n?', '\n', response_text, flags=re.IGNORECASE)
                    # Eliminar tambi√©n cuando aparece en medio de una l√≠nea
                    response_text = re.sub(rf'{re.escape(phrase)}[:\s]*', '', response_text, flags=re.IGNORECASE)
                
                # LIMPIEZA AGRESIVA: Detectar y eliminar fragmentos copiados de documentos
                # Primero, detectar patrones espec√≠ficos de texto copiado
                
                # Patr√≥n 1: "Cuidado de X Descripci√≥n General" seguido de texto t√©cnico
                response_text = re.sub(
                    r'Cuidado de [A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±\s]+ Descripci√≥n General[^\n]*\n?',
                    '',
                    response_text,
                    flags=re.IGNORECASE | re.MULTILINE
                )
                
                # Patr√≥n 2: L√≠neas que empiezan con t√≠tulos t√©cnicos conocidos
                technical_titles = [
                    r'^Descripci√≥n General[:\s]*',
                    r'^Propagaci√≥n por Semillas[:\s]*',
                    r'^Ventajas[:\s]*-',
                    r'^Desventajas[:\s]*-',
                    r'^M√©todo B√°sico[:\s]*',
                    r'^Problemas Comunes[:\s]*-',
                    r'^Trasplante Frecuencia[:\s]*-',
                    r'^Procedimiento[:\s]*\d+\.',
                    r'^Cuidado de Suculentas[:\s]*',
                    r'^Cuidado de Cactus[:\s]*',
                ]
                for pattern in technical_titles:
                    response_text = re.sub(pattern, '', response_text, flags=re.MULTILINE | re.IGNORECASE)
                
                # Patr√≥n 3: Fragmentos que parecen listas t√©cnicas copiadas
                # Detectar l√≠neas que son solo "n√∫mero. texto corto" o "guion texto corto"
                lines = response_text.split('\n')
                cleaned_final = []
                skip_technical_block = False
                
                for i, line in enumerate(lines):
                    stripped = line.strip()
                    if not stripped:
                        if cleaned_final and cleaned_final[-1].strip():
                            cleaned_final.append('')
                        skip_technical_block = False
                        continue
                    
                    # Detectar inicio de bloque t√©cnico (t√≠tulos conocidos)
                    if any(title in stripped for title in ['Descripci√≥n General', 'Propagaci√≥n por Semillas', 
                                                           'Ventajas', 'Desventajas', 'M√©todo B√°sico', 
                                                           'Problemas Comunes', 'Trasplante Frecuencia', 'Procedimiento']):
                        skip_technical_block = True
                        continue
                    
                    # Si estamos en un bloque t√©cnico, saltar l√≠neas que parecen t√©cnicas
                    if skip_technical_block:
                        # Detectar si la l√≠nea es parte de una lista t√©cnica
                        is_technical_line = (
                            re.match(r'^[\d\.\-\‚Ä¢\*]+\s+[A-Z]', stripped) or  # Empieza con n√∫mero/guion y may√∫scula
                            re.match(r'^[A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±\s]+:\s*[A-Z]', stripped) or  # "T√≠tulo: Texto"
                            (stripped.count('- ') > 0 and len(stripped) < 80) or  # Lista con guiones corta
                            (re.match(r'^\d+\.\s+', stripped) and len(stripped) < 50)  # Pasos numerados cortos
                        )
                        if is_technical_line:
                            continue
                        else:
                            # Si encontramos texto normal, salir del bloque t√©cnico
                            skip_technical_block = False
                    
                    # Si la l√≠nea empieza con un n√∫mero y punto, verificar que tenga suficiente contenido
                    if re.match(r'^\d+\.\s+', stripped):
                        content = re.sub(r'^\d+\.\s+', '', stripped)
                        # Solo mantener si tiene contenido sustancial Y no parece copiado
                        if len(content) > 15 and not any(indicator in content for indicator in 
                                                         ['Corte limpio', 'horizontal ambos', 'Sacar de maceta']):
                            cleaned_final.append(line)
                    elif stripped and not re.match(r'^[\d\.\-\‚Ä¢\*]+$', stripped):
                        # Verificar que no sea un fragmento t√©cnico aislado
                        if not (len(stripped) < 30 and any(indicator in stripped for indicator in 
                                                          ['Corte limpio', 'horizontal ambos', 'Quemaduras solares',
                                                           'Cochinillas y √°fidos', 'Hojas blandas'])):
                            cleaned_final.append(line)
                
                response_text = '\n'.join(cleaned_final).strip()
                
                # Eliminar fragmentos espec√≠ficos problem√°ticos que se detectaron
                problematic_fragments = [
                    r'Corte limpio horizontal ambos \d+',
                    r'Cuidado de Suculentas Descripci√≥n General',
                    r'Hojas blandas y amarillas desde la base',
                    r'Quemaduras solares: Manchas marrones',
                ]
                for fragment in problematic_fragments:
                    response_text = re.sub(fragment, '', response_text, flags=re.IGNORECASE)
                
                # Detectar y eliminar bloques de texto que parecen venir directamente de documentos
                # Dividir en p√°rrafos y analizar cada uno
                paragraphs = response_text.split('\n\n')
                cleaned_paragraphs = []
                for para in paragraphs:
                    para_stripped = para.strip()
                    if not para_stripped:
                        continue
                    
                    # Detectar p√°rrafos que son claramente copiados de documentos
                    # Si contiene m√∫ltiples indicadores de documentos o estructura t√©cnica
                    document_indicators_count = sum(1 for indicator in [
                        'Descripci√≥n General', 'Propagaci√≥n por Semillas', 'Ventajas', 'Desventajas',
                        'M√©todo B√°sico', 'Problemas Comunes', 'Trasplante Frecuencia', 'Procedimiento',
                        'Cuidado de Suculentas', 'Cuidado de Cactus', 'Plantas de Interior Comunes',
                        'Hojas blandas y amarillas', 'Quemaduras solares', 'Cochinillas y √°fidos'
                    ] if indicator in para_stripped)
                    
                    # Si tiene m√°s de 1 indicador, probablemente es texto copiado
                    if document_indicators_count > 1:
                        print(f"‚ö†Ô∏è Detectado p√°rrafo copiado de documento (indicadores: {document_indicators_count})")
                        continue
                    
                    # Si el p√°rrafo empieza con un t√≠tulo t√©cnico conocido, saltarlo
                    first_line = para_stripped.split('\n')[0].strip()
                    if first_line in ['Descripci√≥n General', 'Propagaci√≥n por Semillas', 'Ventajas', 
                                     'Desventajas', 'M√©todo B√°sico', 'Problemas Comunes', 
                                     'Trasplante Frecuencia', 'Procedimiento']:
                        continue
                    
                    # Si el p√°rrafo es muy t√©cnico y estructurado (muchos guiones o n√∫meros), puede ser copiado
                    if para_stripped.count('- ') > 3 and len(para_stripped.split('\n')) > 2:
                        # Verificar si parece una lista t√©cnica copiada
                        lines_in_para = para_stripped.split('\n')
                        technical_lines = sum(1 for line in lines_in_para if re.match(r'^[\s]*[-‚Ä¢]\s+[A-Z]', line))
                        if technical_lines > 2:
                            print(f"‚ö†Ô∏è Detectado p√°rrafo con estructura t√©cnica copiada")
                            continue
                    
                    cleaned_paragraphs.append(para)
                
                response_text = '\n\n'.join(cleaned_paragraphs).strip()
                
                # Limpiar espacios m√∫ltiples y saltos de l√≠nea
                response_text = re.sub(r'\n{3,}', '\n\n', response_text)
                response_text = re.sub(r' {2,}', ' ', response_text)
                response_text = response_text.strip()
                
                # LIMPIEZA FINAL: Eliminar cualquier fragmento restante que parezca copiado
                # Dividir en oraciones y filtrar las que parecen fragmentos t√©cnicos
                sentences = re.split(r'[.!?]\s+', response_text)
                cleaned_sentences = []
                for sent in sentences:
                    sent_stripped = sent.strip()
                    if not sent_stripped or len(sent_stripped) < 10:
                        continue
                    
                    # Detectar oraciones que son fragmentos t√©cnicos
                    is_fragment = (
                        sent_stripped.startswith('Corte limpio') or
                        sent_stripped.startswith('horizontal ambos') or
                        sent_stripped.startswith('Sacar de maceta') or
                        'Cuidado de Suculentas' in sent_stripped or
                        'Cuidado de Cactus' in sent_stripped or
                        'Descripci√≥n General' in sent_stripped or
                        (len(sent_stripped) < 30 and any(indicator in sent_stripped for indicator in 
                                                         ['Quemaduras solares', 'Cochinillas', 'Hojas blandas']))
                    )
                    
                    if not is_fragment:
                        cleaned_sentences.append(sent_stripped)
                
                if cleaned_sentences:
                    response_text = '. '.join(cleaned_sentences)
                    if response_text[-1] not in '.!?':
                        response_text += '.'
                else:
                    # Si se elimin√≥ todo, usar el texto original pero con limpieza b√°sica
                    response_text = re.sub(r'Cuidado de [A-Z√Å√â√ç√ì√ö√ë][a-z√°√©√≠√≥√∫√±\s]+ Descripci√≥n General[^\n]*', '', response_text, flags=re.IGNORECASE)
                    response_text = re.sub(r'Corte limpio horizontal ambos \d+', '', response_text, flags=re.IGNORECASE)
                
                # Si la respuesta termina abruptamente, agregar punto final
                if response_text and response_text[-1] not in '.!?':
                    response_text += '.'
                
                # Validaci√≥n final - si todav√≠a tiene problemas, intentar una limpieza m√°s agresiva
                if re.search(r'#{1,6}', response_text) or len(response_text) < 50:
                    print("‚ö†Ô∏è Respuesta a√∫n tiene problemas despu√©s de limpieza")
                    # Eliminar completamente cualquier l√≠nea con #
                    final_clean = []
                    for line in response_text.split('\n'):
                        if '#' not in line and len(line.strip()) > 5:
                            final_clean.append(line)
                    if final_clean:
                        response_text = '\n'.join(final_clean).strip()
                
                print(f"‚úÖ Respuesta del LLM generada ({len(response_text)} caracteres)")
                
                # Verificar si la respuesta indica que est√° fuera del conocimiento
                if not documents or (documents and max([d['relevance_score'] for d in documents]) < 0.4):
                    # Baja relevancia, verificar si la pregunta es sobre plantas
                    if not any(word in request.message.lower() for word in ['planta', 'planta', 'flor', 'hoja', 'riego', 'cuidado', 'suelo', 'luz', 'agua', 'maceta', 'jard√≠n', 'verde', 'semilla', 'ra√≠z', 'tallo', 'bonsai', 'suculenta', 'cactus', 'tropical']):
                        response_text = f"Lo siento, pero esa pregunta no est√° relacionada con plantas. Soy un asistente especializado en cuidado de plantas. Puedo ayudarte con:\n\n‚Ä¢ Identificaci√≥n de plantas\n‚Ä¢ Cuidado y mantenimiento\n‚Ä¢ Problemas de salud de plantas\n‚Ä¢ Recomendaciones de riego, luz y suelo\n‚Ä¢ Tratamiento de plagas\n\n¬øTienes alguna pregunta sobre plantas que pueda ayudarte a resolver?"
                
                return JSONResponse(
                    status_code=200,
                    content={
                        "success": True,
                        "response": response_text
                    }
                )
            except Exception as e:
                error_str = str(e)
                print(f"‚ùå Error generando respuesta con LLM: {e}")
                
                # Detectar si es error de quota (429) o ResourceExhausted
                is_quota_error = (
                    "429" in error_str or 
                    "ResourceExhausted" in error_str or 
                    "quota" in error_str.lower() or
                    "exceeded" in error_str.lower()
                )
                
                if is_quota_error:
                    print("‚ö†Ô∏è Quota de Gemini agotada - deshabilitando LLM para esta sesi√≥n")
                    # Deshabilitar LLM para evitar m√°s intentos
                    response_agent.llm = None
                    global gemini_available
                    gemini_available = False
                
                import traceback
                traceback.print_exc()
                
                # Fallback: Intentar LLM local primero, luego documentos
                print("‚ö†Ô∏è Gemini LLM no disponible o fall√≥")
                
                # Intentar usar LLM local si est√° disponible (ya declarado como global al inicio de la funci√≥n)
                if local_llm and local_llm.available:
                    print(f"ü§ñ Intentando generar respuesta con LLM local ({local_llm.model})...")
                    try:
                        # Construir prompt similar al de Gemini pero m√°s simple
                        local_prompt = f"""Eres un experto en cuidado de plantas. Responde de forma natural y conversacional.

HISTORIAL:
{history_context if history_context else "Primera pregunta."}

INFORMACI√ìN DE REFERENCIA:
{knowledge_context[:1500] if knowledge_context else "No hay informaci√≥n espec√≠fica disponible."}

PREGUNTA: {request.message}

Responde de forma natural, sin usar s√≠mbolos #, sin copiar texto directamente. Explica con tus propias palabras:"""
                        
                        local_response = local_llm.generate(
                            prompt=local_prompt,
                            max_tokens=800,
                            temperature=0.8
                        )
                        
                        if local_response:
                            # Aplicar limpieza b√°sica
                            local_response = re.sub(r'#{1,6}\s+', '', local_response)
                            local_response = re.sub(r'\.\.\.+', '', local_response)
                            local_response = re.sub(r'\s+', ' ', local_response).strip()
                            
                            if len(local_response) > 50:
                                print(f"‚úÖ Respuesta generada con LLM local ({len(local_response)} caracteres)")
                                return JSONResponse(
                                    status_code=200,
                                    content={
                                        "success": True,
                                        "response": local_response
                                    }
                                )
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error con LLM local: {e}")
                
                # Si LLM local fall√≥ o no est√° disponible, usar documentos o modo demo
                print("üìù LLM local no disponible - usando procesador de documentos o modo demo")
                if documents and max([d['relevance_score'] for d in documents]) >= 0.25:
                    print(f"üìù Usando procesador inteligente de documentos con {len(documents)} documentos")
                    
                    try:
                        from src.document_processor import DocumentProcessor
                        processor = DocumentProcessor()
                        response_text = processor.extract_relevant_info(request.message, documents)
                        
                        if response_text:
                            # Limpiar respuesta final
                            response_text = re.sub(r'\s+', ' ', response_text)
                            if not response_text.endswith('.'):
                                response_text += '.'
                            response_text += '\n\n¬øTe gustar√≠a saber m√°s sobre alg√∫n aspecto espec√≠fico?'
                            
                            return JSONResponse(
                                status_code=200,
                                content={
                                    "success": True,
                                    "response": response_text
                                }
                            )
                    except ImportError:
                        print("‚ö†Ô∏è DocumentProcessor no disponible, usando m√©todo simple")
                        # Fallback a m√©todo simple
                        pass
                    
                    # M√©todo simple si el procesador no est√° disponible
                    import re
                    relevant_docs = [d for d in documents if d['relevance_score'] >= 0.25]
                    all_text = []
                    for doc in relevant_docs[:3]:
                        doc_text = doc['text']
                        doc_text = re.sub(r'^#{1,6}\s+', '', doc_text, flags=re.MULTILINE)
                        doc_text = re.sub(r'#{1,6}\s+', '', doc_text)
                        doc_text = re.sub(r'\.\.\.+', '', doc_text)
                        lines = [l.strip() for l in doc_text.split('\n') if l.strip() and len(l.strip()) > 10]
                        doc_text = ' '.join(lines)
                        if doc_text:
                            all_text.append(doc_text[:500])
                    
                    if all_text:
                        combined = ' '.join(all_text[:2])
                        combined = re.sub(r'\s+', ' ', combined)
                        response_text = combined[:800]
                        if len(combined) > 800:
                            response_text += '...'
                        response_text += '\n\n¬øTe gustar√≠a saber m√°s sobre alg√∫n aspecto espec√≠fico?'
                        
                        return JSONResponse(
                            status_code=200,
                            content={
                                "success": True,
                                "response": response_text
                            }
                        )
                
                # Si no hay documentos relevantes, usar modo demo
                print("üìù No se encontraron documentos relevantes - usando modo demo")
                try:
                    from demo_mode import get_demo_response
                    response_text = get_demo_response(request.message)
                    print("‚úÖ Respuesta generada con modo demo")
                    return JSONResponse(
                        status_code=200,
                        content={
                            "success": True,
                            "response": response_text
                        }
                    )
                except ImportError:
                    print("‚ö†Ô∏è Modo demo no disponible")
                    return JSONResponse(
                        status_code=200,
                        content={
                            "success": True,
                            "response": "Lo siento, no encontr√© informaci√≥n espec√≠fica sobre esa pregunta en mi base de conocimiento. Por favor, intenta reformular tu pregunta o pregunta sobre otro aspecto del cuidado de plantas."
                        }
                    )
        else:
            # Sin LLM, usar procesador inteligente de documentos
            if documents and max([d['relevance_score'] for d in documents]) >= 0.25:
                try:
                    from src.document_processor import DocumentProcessor
                    processor = DocumentProcessor()
                    response_text = processor.extract_relevant_info(request.message, documents)
                    
                    if response_text:
                        import re
                        response_text = re.sub(r'\s+', ' ', response_text)
                        if not response_text.endswith('.'):
                            response_text += '.'
                        response_text += '\n\n¬øTe gustar√≠a saber m√°s sobre alg√∫n aspecto espec√≠fico?'
                        
                        return JSONResponse(
                            status_code=200,
                            content={
                                "success": True,
                                "response": response_text
                            }
                        )
                except ImportError:
                    print("‚ö†Ô∏è DocumentProcessor no disponible, usando m√©todo simple")
                    pass
            
            # M√©todo simple o modo demo
            if documents:
                import re
                # Combinar informaci√≥n de m√∫ltiples documentos
                combined_info = []
                for doc in documents[:3]:
                    doc_text = doc['text']
                    # Limpiar markdown
                    doc_text = re.sub(r'^#{1,6}\s+', '', doc_text, flags=re.MULTILINE)
                    doc_text = re.sub(r'#{1,6}\s+', '', doc_text)
                    doc_text = re.sub(r'\.\.\.+', '', doc_text)
                    # Eliminar l√≠neas vac√≠as o muy cortas
                    lines = [l.strip() for l in doc_text.split('\n') if l.strip() and len(l.strip()) > 15]
                    doc_text = ' '.join(lines)
                    combined_info.append(doc_text)
                
                # Crear respuesta estructurada
                full_text = ' '.join(combined_info)
                
                # Extraer informaci√≥n relevante seg√∫n la pregunta
                response_parts = []
                
                # Informaci√≥n general sobre suculentas
                if 'suculent' in request.message.lower():
                    response_parts.append("Las suculentas son plantas que almacenan agua en sus hojas y tallos, lo que las hace muy resistentes y perfectas para principiantes.")
                
                # Extraer informaci√≥n espec√≠fica
                topics = {
                    'riego': ['riego', 'agua', 'regar', 'humedad'],
                    'luz': ['luz', 'sol', 'iluminaci√≥n', 'sombra'],
                    'suelo': ['suelo', 'tierra', 'drenaje', 'maceta'],
                    'temperatura': ['temperatura', 'fr√≠o', 'calor', 'clima'],
                    'propagaci√≥n': ['propagaci√≥n', 'reproducir', 'semilla', 'esqueje']
                }
                
                for topic, keywords in topics.items():
                    relevant_sentences = []
                    for sentence in full_text.split('.'):
                        sentence = sentence.strip()
                        if any(kw in sentence.lower() for kw in keywords) and 20 < len(sentence) < 200:
                            relevant_sentences.append(sentence)
                    
                    if relevant_sentences:
                        # Tomar las 2 m√°s relevantes
                        topic_info = '. '.join(relevant_sentences[:2])
                        # Limpiar markdown residual
                        topic_info = re.sub(r'#{1,6}\s+', '', topic_info)
                        if topic_info:
                            response_parts.append(topic_info + '.')
                
                # Si no encontramos informaci√≥n espec√≠fica, usar las primeras oraciones √∫tiles
                if len(response_parts) < 2:
                    sentences = [s.strip() for s in full_text.split('.') if 30 < len(s.strip()) < 250][:4]
                    if sentences:
                        response_parts.extend(sentences[:2])
                
                if response_parts:
                    response_text = ' '.join(response_parts)
                    # Limpieza final
                    response_text = re.sub(r'#{1,6}\s+', '', response_text)
                    response_text = re.sub(r'\.\.\.+', '', response_text)
                    response_text = re.sub(r'\s+', ' ', response_text)
                    if not response_text.endswith('.'):
                        response_text += '.'
                    response_text += '\n\n¬øTe gustar√≠a saber m√°s sobre alg√∫n aspecto espec√≠fico?'
                else:
                    # Fallback a modo demo
                    try:
                        from demo_mode import get_demo_response
                        response_text = get_demo_response(request.message)
                    except ImportError:
                        response_text = "Encontr√© informaci√≥n sobre suculentas en mi base de conocimiento. Las suculentas requieren poco mantenimiento y son muy resistentes. ¬øTe gustar√≠a que te explique alg√∫n aspecto espec√≠fico del cuidado de suculentas?"
                
                return JSONResponse(
                    status_code=200,
                    content={
                        "success": True,
                        "response": response_text
                    }
                )
            else:
                # Sin documentos, usar modo demo
                try:
                    from demo_mode import get_demo_response
                    response_text = get_demo_response(request.message)
                except ImportError:
                    response_text = "No encontr√© informaci√≥n espec√≠fica sobre esa pregunta. Por favor, intenta hacer preguntas sobre cuidado de plantas, identificaci√≥n de especies, problemas comunes, o recomendaciones de mantenimiento."
                
                return JSONResponse(
                    status_code=200,
                    content={
                        "success": True,
                        "response": response_text
                    }
                )
    
    except Exception as e:
        print(f"‚ùå Error en chat: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"Error procesando mensaje: {str(e)}"
        )


@app.get("/api/stats")
async def get_stats():
    """Estad√≠sticas del sistema"""
    return {
        "total_agents": 4,
        "agents": [
            "VisionAgent (Gemini Vision + Plant.id)",
            "KnowledgeAgent (Supabase pgvector)",
            "AnalysisAgent (Diagn√≥stico)",
            "ResponseAgent (Orquestador LangChain)"
        ],
        "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
        "llm": "Google Gemini Pro"
    }


if __name__ == "__main__":
    # Configuraci√≥n del servidor
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", 8000))
    debug = os.getenv("DEBUG", "True").lower() == "true"
    
    print("=" * 60)
    print("üå± PlantCare AI Backend")
    print("=" * 60)
    print(f"üåê Host: {host}")
    print(f"üîå Puerto: {port}")
    print(f"üêõ Debug: {debug}")
    print("=" * 60)
    print("\nüì° Endpoints disponibles:")
    print(f"  - GET  http://{host}:{port}/")
    print(f"  - GET  http://{host}:{port}/api/health")
    print(f"  - POST http://{host}:{port}/api/analyze-plant")
    print(f"  - POST http://{host}:{port}/api/chat")
    print(f"  - GET  http://{host}:{port}/api/stats")
    print(f"  - GET  http://{host}:{port}/docs (Swagger UI)")
    print("\n")
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=debug
    )
