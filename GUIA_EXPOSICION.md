# ğŸŒ± PlantCare AI - GuÃ­a de ExposiciÃ³n
## Proyecto Final - IntroducciÃ³n a la Inteligencia Artificial

---

## ğŸ“‹ Ãndice de PresentaciÃ³n (15 minutos)

### **Persona 1: Arquitectura y Fundamentos (7.5 min)**
1. IntroducciÃ³n al proyecto (1 min)
2. Arquitectura Multi-Agente (2 min)
3. Componentes fundamentales: Embeddings y Supabase (2 min)
4. Flujo de datos y conexiones (2.5 min)

### **Persona 2: ImplementaciÃ³n y DemostraciÃ³n (7.5 min)**
5. LangChain y orquestaciÃ³n (2 min)
6. Ejemplos de cÃ³digo clave (3 min)
7. DemostraciÃ³n prÃ¡ctica (2 min)
8. Conclusiones (0.5 min)

---

## ğŸ¯ Puntos Clave a Destacar

### âœ… Componentes MÃ­nimos Cumplidos:
1. âœ… **Fuente de datos**: Documentos de plantas en Supabase
2. âœ… **ExtracciÃ³n**: APIs (Plant.id, Gemini Vision)
3. âœ… **SegmentaciÃ³n (chunks)**: Texto dividido en fragmentos
4. âœ… **Embeddings y similitud**: sentence-transformers + pgvector
5. âœ… **Base de datos vectorial**: Supabase con pgvector
6. âœ… **Arquitectura multiagente en LangChain**: 4 agentes coordinados
7. âœ… **Interfaz**: Frontend web interactivo

---

## ğŸ—ï¸ ARQUITECTURA MULTI-AGENTE

### Diagrama de Flujo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USUARIO (Imagen + Pregunta)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGENTE ORQUESTADOR (ResponseAgent)              â”‚
â”‚              Usa LangChain AgentExecutor                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚              â”‚              â”‚              â”‚
       â–¼              â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENTE   â”‚  â”‚   AGENTE     â”‚  â”‚ AGENTE   â”‚  â”‚   LLM        â”‚
â”‚ VISIÃ“N   â”‚  â”‚ CONOCIMIENTO â”‚  â”‚ ANÃLISIS â”‚  â”‚ (Gemini/     â”‚
â”‚          â”‚  â”‚              â”‚  â”‚          â”‚  â”‚  Ollama)     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚                â”‚
     â”‚                â”‚                â”‚                â”‚
     â–¼                â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Plant.id â”‚  â”‚  SUPABASE    â”‚  â”‚ Reglas   â”‚  â”‚ GeneraciÃ³n   â”‚
â”‚ API      â”‚  â”‚  (pgvector)  â”‚  â”‚ LÃ³gica   â”‚  â”‚ Respuesta    â”‚
â”‚ Gemini   â”‚  â”‚  Embeddings   â”‚  â”‚          â”‚  â”‚ Final        â”‚
â”‚ Vision   â”‚  â”‚  BÃºsqueda    â”‚  â”‚          â”‚  â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– AGENTES Y SUS RESPONSABILIDADES

### 1. **AGENTE DE VISIÃ“N** (`agente_vision.py`)
**Responsabilidad**: Analizar imÃ¡genes de plantas

**Flujo**:
1. Recibe imagen de la planta
2. **Plant.id API** â†’ Identifica especie + probabilidad
3. **Gemini Vision** â†’ Analiza salud visual (manchas, color, plagas)
4. Retorna: especie, estado de salud, problemas visuales

**CÃ³digo clave a mostrar**:
```python
def identify_plant_species(self, image_path: str):
    # 1. Plant.id API
    response = requests.post(url, json=data, headers=headers)
    species = result['suggestions'][0]['plant_name']
    
    # 2. Gemini Vision (fallback)
    response = self.gemini_model.generate_content([prompt, img])
    return species_info
```

---

### 2. **AGENTE DE CONOCIMIENTO** (`agente_conocimiento.py`)
**Responsabilidad**: Buscar informaciÃ³n relevante en base vectorial

**Flujo**:
1. Recibe: especie identificada + problemas visuales
2. **Genera embedding** de la consulta usando `sentence-transformers`
3. **BÃºsqueda vectorial** en Supabase usando `pgvector`
4. Retorna: Top 5 documentos mÃ¡s relevantes

**CÃ³digo clave a mostrar**:
```python
def search_knowledge(self, query, species, problems):
    # 1. Generar embedding
    query_embedding = self.embedder.encode(query)
    
    # 2. BÃºsqueda vectorial en Supabase
    results = supabase.rpc('match_plant_documents', {
        'query_embedding': query_embedding.tolist(),
        'match_threshold': 0.3,
        'match_count': 5
    }).execute()
    
    return documents
```

**Conceptos clave**:
- **Embeddings**: RepresentaciÃ³n numÃ©rica del texto (384 dimensiones)
- **Similitud del coseno**: Compara embeddings para encontrar documentos similares
- **pgvector**: ExtensiÃ³n de PostgreSQL para bÃºsqueda vectorial

---

### 3. **AGENTE DE ANÃLISIS** (`agente_analisis.py`)
**Responsabilidad**: Diagnosticar problemas y calcular salud

**Flujo**:
1. Combina: datos visuales + conocimiento recuperado + acciones del usuario
2. Aplica reglas de diagnÃ³stico (exceso de riego, falta de luz, etc.)
3. Calcula puntuaciÃ³n de salud (1-10)
4. Genera diagnÃ³stico estructurado

**CÃ³digo clave a mostrar**:
```python
def execute(self, vision_result, knowledge_result, user_actions):
    # AnÃ¡lisis de problemas
    issues = []
    if "riego cada dÃ­a" in user_actions.lower():
        issues.append({'type': 'exceso_de_riego', 'severity': 7})
    
    # CÃ¡lculo de salud
    health_score = vision_score - (problemas Ã— 0.5) - (severidad Ã— 0.3)
    
    return {
        'health_score': health_score,
        'diagnosis': diagnosis,
        'identified_issues': issues
    }
```

---

### 4. **AGENTE DE RESPUESTA** (`agente_respuesta.py` / `agente_respuesta_langchain.py`)
**Responsabilidad**: Orquestar todos los agentes y generar respuesta final

**Flujo con LangChain**:
1. Crea **Tools** para cada agente
2. Usa **AgentExecutor** de LangChain para coordinar
3. **LLM (Gemini/Ollama)** genera recomendaciones finales
4. Combina toda la informaciÃ³n en respuesta estructurada

**CÃ³digo clave a mostrar**:
```python
# LangChain AgentExecutor
tools = [
    Tool(name="vision_analysis", func=vision_tool, ...),
    Tool(name="knowledge_search", func=knowledge_tool, ...),
    Tool(name="plant_analysis", func=analysis_tool, ...)
]

agent = create_structured_chat_agent(llm=self.llm, tools=tools, prompt=prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory)

# Ejecutar
result = agent_executor.invoke({"input": "Analiza esta planta..."})
```

---

## ğŸ”— CONEXIÃ“N CON SUPABASE

### Base de Datos Vectorial

**Estructura**:
```sql
CREATE TABLE plant_documents (
    id BIGSERIAL PRIMARY KEY,
    chunk_id TEXT NOT NULL,
    text TEXT NOT NULL,
    embedding vector(384),  -- pgvector
    source_file TEXT,
    created_at TIMESTAMP
);
```

**Flujo de bÃºsqueda**:
1. Usuario pregunta: "Â¿CÃ³mo cuido una suculenta?"
2. Sistema genera embedding de la pregunta
3. BÃºsqueda en Supabase usando similitud del coseno
4. Retorna documentos mÃ¡s relevantes (top 5)

**CÃ³digo a mostrar**:
```python
# Generar embedding
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode("Â¿CÃ³mo cuido una suculenta?")

# BÃºsqueda en Supabase
results = supabase.rpc('match_plant_documents', {
    'query_embedding': embedding.tolist(),
    'match_threshold': 0.3,
    'match_count': 5
}).execute()
```

---

## ğŸ§  LLM (Large Language Model)

### Â¿QuÃ© es un LLM?
Modelo de lenguaje que genera texto basado en contexto.

### Â¿CÃ³mo lo usamos?
1. **Gemini (Google)**: Principal, para anÃ¡lisis y recomendaciones
2. **Ollama (Local)**: Fallback cuando Gemini no estÃ¡ disponible
3. **Sin LLM**: Usa solo documentos de Supabase

### IntegraciÃ³n con LangChain:
```python
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.7
)

# Generar recomendaciones
prompt = f"""
Eres un experto en plantas. BasÃ¡ndote en:
- Especie: {species}
- DiagnÃ³stico: {diagnosis}
- Conocimiento: {context}

Genera 3-5 recomendaciones especÃ­ficas.
"""

response = llm.generate_content(prompt)
```

---

## ğŸ“ SCRIPT DE PRESENTACIÃ“N

### **PERSONA 1 (7.5 minutos)**

#### **1. IntroducciÃ³n (1 min)**
"Hola, somos [Nombres]. Hoy presentamos **PlantCare AI**, un sistema de inteligencia artificial que ayuda a cuidar plantas mediante anÃ¡lisis de imÃ¡genes y conocimiento especializado."

#### **2. Arquitectura Multi-Agente (2 min)**
"El sistema usa una **arquitectura de 4 agentes especializados** coordinados con LangChain:

- **Agente de VisiÃ³n**: Analiza imÃ¡genes usando Plant.id API y Gemini Vision
- **Agente de Conocimiento**: Busca informaciÃ³n en nuestra base de datos vectorial
- **Agente de AnÃ¡lisis**: Diagnostica problemas y calcula salud
- **Agente de Respuesta**: Orquesta todo y genera la respuesta final

*[Mostrar diagrama de flujo]*"

#### **3. Embeddings y Supabase (2 min)**
"Para buscar informaciÃ³n relevante, usamos **embeddings** - representaciones numÃ©ricas del texto. 

*[Mostrar cÃ³digo de embeddings]*

Convertimos las preguntas del usuario en vectores de 384 dimensiones usando `sentence-transformers`. Luego buscamos en **Supabase con pgvector** documentos similares usando similitud del coseno.

*[Mostrar cÃ³digo de bÃºsqueda en Supabase]*

Esto nos permite encontrar informaciÃ³n relevante incluso si el usuario no usa las palabras exactas de nuestros documentos."

#### **4. Flujo de Datos (2.5 min)**
"Cuando un usuario sube una imagen:

1. El **Agente de VisiÃ³n** identifica la especie y analiza la salud
2. El **Agente de Conocimiento** busca informaciÃ³n relevante en Supabase
3. El **Agente de AnÃ¡lisis** combina todo y genera un diagnÃ³stico
4. El **LLM** (Gemini u Ollama) genera recomendaciones personalizadas

*[Mostrar cÃ³digo del flujo en agente_respuesta.py]*

Todo esto se coordina usando **LangChain AgentExecutor**, que permite que los agentes trabajen juntos de forma inteligente."

---

### **PERSONA 2 (7.5 minutos)**

#### **5. LangChain y OrquestaciÃ³n (2 min)**
"LangChain nos permite orquestar los agentes de forma elegante. Creamos **Tools** para cada agente y usamos **AgentExecutor** para coordinar su ejecuciÃ³n.

*[Mostrar cÃ³digo de LangChain]*

El sistema decide automÃ¡ticamente quÃ© agente usar en cada momento, creando un flujo inteligente y dinÃ¡mico."

#### **6. Ejemplos de CÃ³digo Clave (3 min)**

**Ejemplo 1: Agente de VisiÃ³n**
*[Abrir `agente_vision.py`]*
"Este agente combina dos APIs: Plant.id para identificaciÃ³n y Gemini Vision para anÃ¡lisis de salud. Si una falla, usa la otra como respaldo."

**Ejemplo 2: BÃºsqueda Vectorial**
*[Abrir `agente_conocimiento.py`]*
"AquÃ­ vemos cÃ³mo generamos embeddings y buscamos en Supabase. El sistema encuentra documentos relevantes incluso con consultas diferentes."

**Ejemplo 3: LangChain AgentExecutor**
*[Abrir `agente_respuesta_langchain.py`]*
"Este es el corazÃ³n del sistema. Coordina todos los agentes usando LangChain, permitiendo que trabajen juntos de forma inteligente."

#### **7. DemostraciÃ³n PrÃ¡ctica (2 min)**
*[Abrir terminal y mostrar logs del backend]*

"Cuando procesamos una imagen, vemos en los logs cÃ³mo cada agente se ejecuta:
- Vision Agent identifica la planta
- Knowledge Agent busca informaciÃ³n
- Analysis Agent diagnostica
- Response Agent genera recomendaciones

*[Mostrar ejemplo de respuesta completa]*"

#### **8. Conclusiones (0.5 min)**
"El proyecto demuestra la integraciÃ³n exitosa de:
- âœ… Arquitectura multiagente con LangChain
- âœ… Embeddings y bÃºsqueda vectorial
- âœ… IntegraciÃ³n con LLMs (Gemini/Ollama)
- âœ… Base de datos vectorial (Supabase + pgvector)

Gracias por su atenciÃ³n. Â¿Preguntas?"

---

## ğŸ’» CÃ“DIGO CLAVE A MOSTRAR

### 1. **GeneraciÃ³n de Embeddings**
```python
# src/agentes/agente_conocimiento.py (lÃ­neas 30-40)
from embeddings import EmbeddingGenerator

embedder = EmbeddingGenerator()
query_embedding = embedder.generate_embedding("Â¿CÃ³mo cuido una suculenta?")
# Retorna: array de 384 nÃºmeros (vector)
```

### 2. **BÃºsqueda en Supabase**
```python
# src/agentes/agente_conocimiento.py (lÃ­neas 60-80)
results = supabase.rpc('match_plant_documents', {
    'query_embedding': query_embedding.tolist(),
    'match_threshold': 0.3,
    'match_count': 5
}).execute()

# Retorna documentos ordenados por relevancia (similitud del coseno)
```

### 3. **LangChain AgentExecutor**
```python
# src/agentes/agente_respuesta_langchain.py (lÃ­neas 175-250)
from langchain.agents import AgentExecutor, create_structured_chat_agent
from langchain.tools import Tool

tools = [
    Tool(name="vision_analysis", func=vision_tool, ...),
    Tool(name="knowledge_search", func=knowledge_tool, ...),
    Tool(name="plant_analysis", func=analysis_tool, ...)
]

agent = create_structured_chat_agent(llm=llm, tools=tools, prompt=prompt)
executor = AgentExecutor(agent=agent, tools=tools, memory=memory)
result = executor.invoke({"input": "Analiza esta planta..."})
```

### 4. **Uso del LLM**
```python
# src/agentes/agente_respuesta.py (lÃ­neas 110-140)
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash")
response = llm.generate_content(prompt)
recommendations = parse_recommendations(response.text)
```

---

## ğŸ¨ DIAGRAMA PARA MOSTRAR EN PANTALLA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PLANTCARE AI                         â”‚
â”‚         Sistema Multi-Agente con LangChain              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    [Imagen de Planta]
                           â”‚
                           â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   RESPONSE AGENT (LangChain)     â”‚
        â”‚   AgentExecutor + Tools          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚           â”‚
        â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚VISIONâ”‚   â”‚KNOWLEDGEâ”‚   â”‚ANALYSISâ”‚
    â””â”€â”€â”¬â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”˜
       â”‚           â”‚           â”‚
       â–¼           â–¼           â–¼
  [Plant.id]  [Supabase]   [Reglas]
  [Gemini]    [pgvector]   [LÃ³gica]
  Vision      [Embeddings]  [CÃ¡lculos]
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  LLM (Gemini)â”‚
            â”‚  / Ollama    â”‚
            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
            [Recomendaciones]
```

---

## ğŸ“Š MÃ‰TRICAS Y RESULTADOS

### Lo que funciona bien:
- âœ… IdentificaciÃ³n de especies (Plant.id API)
- âœ… BÃºsqueda vectorial precisa (Supabase + pgvector)
- âœ… DiagnÃ³stico automÃ¡tico de problemas
- âœ… Recomendaciones personalizadas con LLM

### Fallbacks implementados:
- Gemini â†’ Ollama (local) â†’ Documentos â†’ Demo Mode
- Plant.id â†’ Gemini Vision
- Sistema funciona incluso sin APIs externas

---

## ğŸ”‘ CONCEPTOS CLAVE PARA EXPLICAR

1. **Embeddings**: "Convertimos texto en nÃºmeros que capturan su significado"
2. **Similitud del coseno**: "Comparamos vectores para encontrar documentos similares"
3. **pgvector**: "ExtensiÃ³n de PostgreSQL para bÃºsqueda vectorial eficiente"
4. **LangChain**: "Framework que coordina agentes y LLMs"
5. **AgentExecutor**: "Orquestador que decide quÃ© agente usar y cuÃ¡ndo"
6. **RAG (Retrieval-Augmented Generation)**: "Buscamos informaciÃ³n relevante antes de generar respuesta"

---

## ğŸ“ ARCHIVOS CLAVE A MENCIONAR

1. `src/agentes/agente_vision.py` - AnÃ¡lisis de imÃ¡genes
2. `src/agentes/agente_conocimiento.py` - BÃºsqueda vectorial
3. `src/agentes/agente_analisis.py` - DiagnÃ³stico
4. `src/agentes/agente_respuesta_langchain.py` - OrquestaciÃ³n con LangChain
5. `src/embeddings.py` - GeneraciÃ³n de embeddings
6. `src/vector_db.py` - ConexiÃ³n con Supabase

---

## âœ… CHECKLIST PRE-EXPOSICIÃ“N

- [ ] Tener diagrama de flujo visible
- [ ] Abrir archivos de cÃ³digo clave
- [ ] Tener terminal con backend corriendo
- [ ] Preparar ejemplo de imagen de planta
- [ ] Tener logs del backend visibles
- [ ] Probar que Supabase responde
- [ ] Verificar que LangChain funciona

---

## ğŸ¯ MENSAJE FINAL

"Este proyecto demuestra cÃ³mo los conceptos fundamentales de IA - embeddings, bÃºsqueda vectorial, y arquitectura multiagente - se combinan para crear un sistema prÃ¡ctico y funcional que ayuda a las personas a cuidar sus plantas de forma inteligente."

---

**Â¡Ã‰xito en la exposiciÃ³n! ğŸŒ±**

