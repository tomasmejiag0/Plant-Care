#  C贸digo para Mostrar en la Exposici贸n

##  Archivos Clave a Abrir

1. `src/agentes/agente_vision.py`
2. `src/agentes/agente_conocimiento.py`
3. `src/agentes/agente_analisis.py`
4. `src/agentes/agente_respuesta_langchain.py`
5. `src/embeddings.py`
6. `main.py` (endpoint principal)

---

##  1. AGENTE DE VISIN (agente_vision.py)

### C贸digo a Mostrar - Identificaci贸n de Planta

```python
def identify_plant_species(self, image_path: str) -> Optional[Dict]:
    """Identifica la especie usando Plant.id API o Gemini Vision"""
    
    # 1. Intentar con Plant.id API
    if self.plant_id_key:
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode('utf-8')
        
        response = requests.post(
            "https://api.plant.id/v2/identify",
            json={"images": [f"data:image/jpeg;base64,{image_data}"]},
            headers={"Api-Key": self.plant_id_key}
        )
        
        result = response.json()
        species = result['suggestions'][0]['plant_name']
        probability = result['suggestions'][0]['probability']
        
        return {'species': species, 'probability': probability}
    
    # 2. Fallback: Gemini Vision
    if self.gemini_model:
        img = Image.open(image_path)
        prompt = "Identifica la especie de esta planta..."
        response = self.gemini_model.generate_content([prompt, img])
        return parse_species(response.text)
```

**Qu茅 explicar:**
- Usa dos APIs diferentes (Plant.id y Gemini Vision)
- Tiene fallback si una falla
- Retorna especie y probabilidad

---

##  2. AGENTE DE CONOCIMIENTO (agente_conocimiento.py)

### C贸digo a Mostrar - Generaci贸n de Embeddings

```python
# src/embeddings.py
from sentence_transformers import SentenceTransformer

class EmbeddingGenerator:
    def __init__(self):
        # Modelo pre-entrenado: 384 dimensiones
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
    
    def generate_embedding(self, text: str) -> np.ndarray:
        """Convierte texto en vector num茅rico"""
        embedding = self.model.encode(text)
        # Retorna: array de 384 n煤meros
        return embedding
```

**Qu茅 explicar:**
- `sentence-transformers` convierte texto en n煤meros
- 384 dimensiones capturan el significado
- Mismo modelo para consultas y documentos

### C贸digo a Mostrar - B煤squeda en Supabase

```python
def search_knowledge(self, query: str, species: str, problems: List[str]):
    """Busca informaci贸n relevante en Supabase"""
    
    # 1. Construir consulta mejorada
    enhanced_query = f"{query} {species} {' '.join(problems)}"
    
    # 2. Generar embedding de la consulta
    query_embedding = self.embedder.generate_embedding(enhanced_query)
    
    # 3. B煤squeda vectorial en Supabase usando pgvector
    results = self.supabase.rpc('match_plant_documents', {
        'query_embedding': query_embedding.tolist(),  # Convertir a lista
        'match_threshold': 0.3,  # Umbral de similitud
        'match_count': 5  # Top 5 documentos
    }).execute()
    
    # 4. Retornar documentos ordenados por relevancia
    documents = []
    for row in results.data:
        documents.append({
            'text': row['text'],
            'relevance_score': row['similarity'],  # Similitud del coseno
            'source': row['source_file']
        })
    
    return documents
```

**Qu茅 explicar:**
- `pgvector` permite b煤squeda vectorial en PostgreSQL
- Similitud del coseno compara vectores
- Retorna documentos m谩s relevantes

---

##  3. AGENTE DE ANLISIS (agente_analisis.py)

### C贸digo a Mostrar - Diagn贸stico

```python
def execute(self, vision_result, knowledge_result, user_actions: str):
    """Combina informaci贸n y genera diagn贸stico"""
    
    identified_issues = []
    
    # Analizar acciones del usuario
    user_lower = user_actions.lower()
    
    if "riego cada d铆a" in user_lower or "riego diario" in user_lower:
        identified_issues.append({
            'type': 'exceso_de_riego',
            'severity': 7,
            'description': 'Riego excesivo detectado'
        })
    
    if "sin luz" in user_lower or "oscuro" in user_lower:
        identified_issues.append({
            'type': 'falta_de_luz',
            'severity': 6,
            'description': 'Falta de iluminaci贸n'
        })
    
    # Calcular puntuaci贸n de salud
    visual_score = vision_result.get('health_score', 5)
    problem_penalty = sum(issue['severity'] for issue in identified_issues) * 0.3
    health_score = max(1, min(10, visual_score - problem_penalty))
    
    # Generar diagn贸stico
    diagnosis = self._generate_diagnosis(identified_issues, vision_result)
    
    return {
        'health_score': health_score,
        'diagnosis': diagnosis,
        'identified_issues': identified_issues
    }
```

**Qu茅 explicar:**
- Combina datos visuales + conocimiento + acciones del usuario
- Aplica reglas de diagn贸stico
- Calcula puntuaci贸n de salud

---

##  4. AGENTE DE RESPUESTA CON LANGCHAIN (agente_respuesta_langchain.py)

### C贸digo a Mostrar - Creaci贸n de Tools

```python
def _create_tools(self):
    """Crea herramientas (Tools) para LangChain"""
    
    def vision_tool(image_path: str, user_actions: str) -> str:
        """Herramienta para an谩lisis visual"""
        result = self.vision_agent.execute(image_path, user_actions)
        return f"Especie: {result['species']}, Salud: {result['health_score']}/10"
    
    def knowledge_tool(query: str, species: str) -> str:
        """Herramienta para b煤squeda de conocimiento"""
        documents = self.knowledge_agent.search_knowledge(query, species)
        return f"Encontr茅 {len(documents)} documentos relevantes"
    
    def analysis_tool(vision_data: dict, knowledge_data: dict) -> str:
        """Herramienta para an谩lisis"""
        result = self.analysis_agent.execute(vision_data, knowledge_data)
        return f"Diagn贸stico: {result['diagnosis']}"
    
    # Crear Tools de LangChain
    tools = [
        Tool(
            name="vision_analysis",
            func=vision_tool,
            description="Analiza im谩genes de plantas"
        ),
        Tool(
            name="knowledge_search",
            func=knowledge_tool,
            description="Busca informaci贸n en base de conocimiento"
        ),
        Tool(
            name="plant_analysis",
            func=analysis_tool,
            description="Realiza an谩lisis y diagn贸stico"
        )
    ]
    
    return tools
```

**Qu茅 explicar:**
- Cada agente se convierte en un Tool de LangChain
- Tools permiten que el LLM decida cu谩ndo usarlos
- Descripci贸n ayuda al LLM a entender qu茅 hace cada tool

### C贸digo a Mostrar - AgentExecutor

```python
def _create_agent_executor(self):
    """Crea el AgentExecutor de LangChain"""
    
    # Prompt template para el agente
    prompt = ChatPromptTemplate.from_messages([
        ("system", """Eres un experto en plantas. Tienes acceso a:
        - vision_analysis: Analiza im谩genes
        - knowledge_search: Busca informaci贸n
        - plant_analysis: Diagnostica problemas
        
        Usa estas herramientas para responder."""),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    
    # Crear agente estructurado
    agent = create_structured_chat_agent(
        llm=self.llm,
        tools=self.tools,
        prompt=prompt
    )
    
    # Crear ejecutor
    agent_executor = AgentExecutor(
        agent=agent,
        tools=self.tools,
        memory=self.memory,  # Memoria de conversaci贸n
        verbose=True,
        handle_parsing_errors=True
    )
    
    return agent_executor
```

**Qu茅 explicar:**
- `AgentExecutor` coordina la ejecuci贸n
- El LLM decide qu茅 tool usar y cu谩ndo
- `memory` mantiene contexto de la conversaci贸n

---

##  5. USO DEL LLM (agente_respuesta.py)

### C贸digo a Mostrar - Generaci贸n de Recomendaciones

```python
def generate_recommendations(self, analysis_result: Dict, context: str, user_question: str = ""):
    """Genera recomendaciones usando LLM"""
    
    # Construir prompt
    prompt = f"""Eres un experto en plantas. Bas谩ndote en:
    
    ANLISIS:
    - Especie: {analysis_result.get('species')}
    - Estado: {analysis_result.get('overall_status')}
    - Diagn贸stico: {analysis_result.get('diagnosis')}
    - Problemas: {analysis_result.get('identified_issues')}
    
    PREGUNTA DEL USUARIO:
    {user_question}
    
    CONOCIMIENTO RELEVANTE:
    {context[:500]}
    
    Genera 3-5 recomendaciones espec铆ficas y accionables.
    Si el usuario tiene una preocupaci贸n espec铆fica, ab贸rdala directamente."""
    
    # Generar con Gemini
    if self.llm:
        response = self.llm.generate_content(prompt)
        recommendations = parse_recommendations(response.text)
        return recommendations
    
    # Fallback: usar solo documentos
    return self._get_default_recommendations(analysis_result, user_question)
```

**Qu茅 explicar:**
- El LLM genera texto basado en contexto
- Prompt incluye an谩lisis completo + conocimiento
- Tiene fallback si LLM no est谩 disponible

---

##  6. FLUJO PRINCIPAL (main.py)

### C贸digo a Mostrar - Endpoint Principal

```python
@app.post("/api/analyze-plant")
async def analyze_plant(
    image: UploadFile = File(...),
    user_actions: str = Form("")
):
    """Endpoint principal: Analiza una imagen de planta"""
    
    # 1. Guardar imagen temporalmente
    temp_file_path = UPLOAD_DIR / f"temp_plant_{unique_id}.jpg"
    with open(temp_file_path, "wb") as buffer:
        shutil.copyfileobj(image.file, buffer)
    
    # 2. Ejecutar sistema multi-agente
    result = response_agent.execute(
        image_path=str(temp_file_path),
        user_actions=user_actions
    )
    
    # 3. Retornar resultado
    return JSONResponse(content=result)
```

**Qu茅 explicar:**
- Endpoint recibe imagen y pregunta del usuario
- Ejecuta el sistema completo de agentes
- Retorna an谩lisis completo

---

##  7. EJEMPLO DE RESULTADO

### Estructura de Respuesta

```python
{
    "success": True,
    "plant_info": {
        "species": "Cestrum nocturnum",
        "common_names": ["night jessamine", "queen of the night"],
        "confidence": 0.32
    },
    "health_assessment": {
        "score": 5,
        "status": "Regular - Requiere atenci贸n"
    },
    "diagnosis": {
        "summary": "La planta presenta un estado general saludable",
        "visual_problems": ["hojas ligeramente amarillas"],
        "identified_issues": [
            {"type": "falta_de_luz", "severity": 6}
        ]
    },
    "recommendations": [
        "Mueve la planta a un lugar con m谩s luz indirecta",
        "Ajusta el riego seg煤n la temporada",
        "Fertiliza durante primavera-verano"
    ]
}
```

---

##  SECUENCIA DE DEMOSTRACIN

### Orden Sugerido para Mostrar C贸digo:

1. **main.py** - Mostrar endpoint principal (30 seg)
2. **agente_respuesta_langchain.py** - Mostrar AgentExecutor (1 min)
3. **agente_vision.py** - Mostrar identificaci贸n (30 seg)
4. **embeddings.py** - Mostrar generaci贸n de embeddings (1 min)
5. **agente_conocimiento.py** - Mostrar b煤squeda en Supabase (1 min)
6. **agente_analisis.py** - Mostrar diagn贸stico (30 seg)
7. **agente_respuesta.py** - Mostrar generaci贸n con LLM (1 min)

**Total: ~6 minutos de c贸digo**

---

##  FRASES PARA USAR AL MOSTRAR CDIGO

- "Aqu铆 vemos c贸mo el agente genera un embedding..."
- "Este c贸digo muestra la b煤squeda vectorial en Supabase..."
- "LangChain AgentExecutor coordina todos estos agentes..."
- "El LLM recibe todo este contexto y genera recomendaciones..."
- "Este fallback asegura que el sistema funcione sin APIs externas..."

---

**隆Usa estos ejemplos de c贸digo para demostrar c贸mo funciona el sistema! **

